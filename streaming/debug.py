# streaming/debug.py
# spark streaming test
from pyspark.sql import SparkSession
import os
import sys

os.environ['PYSPARK_SUBMIT_ARGS'] = '--packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.4.1 pyspark-shell'

# spark session ìƒì„± (kafka ìë™ ë‹¤ìš´ë¡œë“œ í¬í•¨)
spark = SparkSession.builder \
    .appName("SkyWatcher-Debug") \
    .config("spark.jars.packages", "org.apache.spark:spark-sql-kafka-0-10_2.12:3.4.1") \
    .getOrCreate()

## ë¡œê·¸ ë ˆë²¨ ì¡°ì • (ì§€ì €ë¶„í•œ ë¡œê·¸ ë„ê¸°)
spark.sparkContext.setLogLevel("WARN")

# Kafkaì—ì„œ ë°ì´í„° ì½ê¸° (ReadStream)
df = spark.readStream \
    .format("kafka") \
    .option("kafka.bootstrap.servers", "kafka:29092") \
    .option("subscribe", "raw_flight_data") \
    .option("startingOffsets", "latest") \
    .load()

## Kafka ë°ì´í„°ëŠ” key, valueê°€ ë°”ì´ë„ˆë¦¬ë¡œ ì˜´ -> Stringìœ¼ë¡œ ë³€í™˜
df_string = df.selectExpr("CAST(key AS STRING)", "CAST(value AS STRING)")

# ì½˜ì†” ì¶œë ¥
query = df_string.writeStream \
    .outputMode("append") \
    .format("console") \
    .option("truncate", False) \
    .start()

print("ğŸš€ Spark Streamingì´ Kafka ë°ì´í„°ë¥¼ ê¸°ë‹¤ë¦¬ëŠ” ì¤‘...")
query.awaitTermination()